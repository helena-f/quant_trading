{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e6155b-47c1-47e2-b753-57a0fad9811f",
   "metadata": {},
   "source": [
    "# Hidden Markov Model\n",
    "## 1. Theory\n",
    "\n",
    "Sources: \n",
    "- https://www.scirp.org/journal/paperinformation?paperid=82940#:~:text=For%20stock%20traders%2C%20promptly%20predicting,%E2%80%9D%2C%20or%20%E2%80%9CMedium%E2%80%9D.\n",
    "- https://www.youtube.com/watch?v=9-sPm4CfcD0\n",
    "\n",
    "Hidden Markov Models are statistical models that predict observable states using hidden states.\n",
    "\n",
    "Ex. You have three weather patterns: cloudy, sunny, and rainy. They each have their own unique probabilities and patterns. However, suppose we live in a different city, and we cannot see the weather for ourselves. Instead, we have a friend who lives there. Their mood is influenced by the weather, ie. different probabilities of happy or sad based on the cloudy, rainy, and sunny patterns. \n",
    "\n",
    "We compute the joint probability of our friend's mood patterns and their city's weather patterns. Maximizing this joint probability gives us the most likely weather sequence given the observed mood sequence. \n",
    "\n",
    "$$\\underset{X = X_1, X_2, ..., X_n}{\\operatorname{argmax}} P(X = X_1, X_2, ..., X_n) | Y = Y_1, Y_2, ... Y_n)\n",
    "$$\n",
    "\n",
    "This is difficult to find, so we use Bayes' Theorem.\n",
    "$$\\underset{X = X_1, X_2, ..., X_n}{\\operatorname{argmax}} P(Y | X)P(X) / P(Y)\n",
    "$$\n",
    "\n",
    "$$\\underset{X = X_1, X_2, ..., X_n}{\\operatorname{argmax}} \\Pi P(Y_i | X_i)P(X_i|X_{i-1})$$\n",
    "\n",
    "\n",
    "## 2. Objective\n",
    "We apply the same concept to predicting stock trends. Our hidden states of prediction are uptrend, downtrend, and flat-trend. Our observable states are the prices, volumes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec3bf83-fe75-4108-99bd-418c322f0da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't do dividing by the change\n",
    "# tasks this week: 1) clean up repo format and documentation 2) fix too small number inputs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Fetch and preprocess data\n",
    "def fetch_stock_data(ticker, start_date, end_date):\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    data.columns = data.columns.get_level_values(0)  # Flatten columns\n",
    "    data['Returns'] = data['Close'].pct_change()\n",
    "    data['Log Returns'] = np.log(1 + data['Returns'])\n",
    "    return data.dropna()\n",
    "\n",
    "# volume, delta of open/close price\n",
    "\n",
    "# Step 2: Prepare features\n",
    "def prepare_features(data):\n",
    "    data['Volatility'] = data['Log Returns'].rolling(window=5).std()\n",
    "    print(data.columns)\n",
    "    features = data[['Log Returns', 'Volatility']].dropna().values  # 2D array\n",
    "    aligned_data = data.dropna(subset=['Log Returns', 'Volatility'])  # Align with features\n",
    "    return aligned_data, features\n",
    "\n",
    "# Step 3: Train HMM\n",
    "def train_hmm(features, n_states):\n",
    "    print(\"Training HMM with features shape:\", features.shape)  \n",
    "    model = GaussianHMM(n_components=n_states, covariance_type=\"diag\", n_iter=1000, random_state=42)\n",
    "    model.fit(features)\n",
    "    hidden_states = model.predict(features)\n",
    "    return model, hidden_states\n",
    "\n",
    "def plot_hidden_states(data, hidden_states, n_states):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for state in range(n_states):\n",
    "        state_data = data[hidden_states == state]\n",
    "        plt.plot(state_data.index, state_data['Close'], '.', label=f\"State {state}\")\n",
    "    plt.title(\"Stock Price by Hidden States\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Close Price\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def simulate_trading(data, hidden_states):\n",
    "    data['State'] = hidden_states\n",
    "    print(data['State'])\n",
    "    print(data.eq(0).sum(axis=1))\n",
    "    data['Signal'] = data['State'].apply(lambda x: 1 if x == 0 else -1)  # Buy in state 0, sell in others\n",
    "    print(data['Signal'])\n",
    "    data['Strategy Returns'] = data['Signal'].shift(1) * data['Returns']\n",
    "    cumulative_strategy_returns = (1 + data['Strategy Returns'].dropna()).cumprod()\n",
    "    cumulative_market_returns = (1 + data['Returns'].dropna()).cumprod()\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.plot(cumulative_strategy_returns, label=\"Strategy Returns\")\n",
    "    plt.plot(cumulative_market_returns, label=\"Market Returns\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Trading Strategy vs. Market\")\n",
    "    plt.show()\n",
    "    \n",
    "def calculate_metrics(data):\n",
    "    # Define actual price movements (up=1, down=0)\n",
    "    data['Actual_Movement'] = (data['Returns'] > 0).astype(int)\n",
    "    \n",
    "    # Define predicted movements based on states\n",
    "    data['Predicted_Movement'] = (data['State'] == 0).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    true_positives = sum((data['Actual_Movement'] == 1) & (data['Predicted_Movement'] == 1))\n",
    "    false_positives = sum((data['Actual_Movement'] == 0) & (data['Predicted_Movement'] == 1))\n",
    "    true_negatives = sum((data['Actual_Movement'] == 0) & (data['Predicted_Movement'] == 0))\n",
    "    false_negatives = sum((data['Actual_Movement'] == 1) & (data['Predicted_Movement'] == 0))\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    accuracy = (true_positives + true_negatives) / len(data)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(\"\\nModel Performance Metrics:\")\n",
    "    print(f\"Precision: {precision:.3f}\")\n",
    "    print(f\"Recall: {recall:.3f}\")\n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"F1 Score: {f1_score:.3f}\")\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(f\"True Positives: {true_positives}\")\n",
    "    print(f\"False Positives: {false_positives}\")\n",
    "    print(f\"True Negatives: {true_negatives}\")\n",
    "    print(f\"False Negatives: {false_negatives}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30fcde67-9297-4566-b3d3-8146470cb21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Fitting a model with 11 free scalar parameters with only 2 data points will result in a degenerate solution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Close', 'High', 'Low', 'Open', 'Volume', 'Returns', 'Log Returns',\n",
      "       'Volatility'],\n",
      "      dtype='object', name='Price')\n",
      "Training HMM with features shape: (1, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_samples=1 should be >= n_clusters=2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Train HMM\u001b[39;00m\n\u001b[1;32m     13\u001b[0m n_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 14\u001b[0m hmm_model, hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_hmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHidden states shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, hidden_states\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Should be (2259,)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Plot Hidden States \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m, in \u001b[0;36mtrain_hmm\u001b[0;34m(features, n_states)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining HMM with features shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, features\u001b[38;5;241m.\u001b[39mshape)  \n\u001b[1;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m GaussianHMM(n_components\u001b[38;5;241m=\u001b[39mn_states, covariance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiag\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(features)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/trading_explore/lib/python3.10/site-packages/hmmlearn/base.py:480\u001b[0m, in \u001b[0;36m_AbstractHMM.fit\u001b[0;34m(self, X, lengths)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lengths \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]])\n\u001b[0;32m--> 480\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check()\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmonitor_\u001b[38;5;241m.\u001b[39m_reset()\n",
      "File \u001b[0;32m~/miniconda3/envs/trading_explore/lib/python3.10/site-packages/hmmlearn/hmm.py:314\u001b[0m, in \u001b[0;36mGaussianHMM._init\u001b[0;34m(self, X, lengths)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_needs_init(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeans_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    311\u001b[0m     kmeans \u001b[38;5;241m=\u001b[39m cluster\u001b[38;5;241m.\u001b[39mKMeans(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components,\n\u001b[1;32m    312\u001b[0m                             random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[1;32m    313\u001b[0m                             n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)  \u001b[38;5;66;03m# sklearn <1.4 backcompat.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     \u001b[43mkmeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeans_ \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mcluster_centers_\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_needs_init(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcovars_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/trading_explore/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/trading_explore/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1473\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[1;32m   1439\u001b[0m \n\u001b[1;32m   1440\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1464\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m   1465\u001b[0m     X,\n\u001b[1;32m   1466\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1470\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1471\u001b[0m )\n\u001b[0;32m-> 1473\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params_vs_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1475\u001b[0m random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[1;32m   1476\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/trading_explore/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1414\u001b[0m, in \u001b[0;36mKMeans._check_params_vs_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_params_vs_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m-> 1414\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params_vs_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_n_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_algorithm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melkan\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/trading_explore/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:878\u001b[0m, in \u001b[0;36m_BaseKMeans._check_params_vs_input\u001b[0;34m(self, X, default_n_init)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_params_vs_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, default_n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;66;03m# n_clusters\u001b[39;00m\n\u001b[1;32m    877\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters:\n\u001b[0;32m--> 878\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    879\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should be >= n_clusters=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    880\u001b[0m         )\n\u001b[1;32m    882\u001b[0m     \u001b[38;5;66;03m# tol\u001b[39;00m\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tol \u001b[38;5;241m=\u001b[39m _tolerance(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol)\n",
      "\u001b[0;31mValueError\u001b[0m: n_samples=1 should be >= n_clusters=2."
     ]
    }
   ],
   "source": [
    "ticker = \"AAPL\"\n",
    "from datetime import datetime, timedelta\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=7)\n",
    "\n",
    "# Fetch and preprocess data\n",
    "stock_data = fetch_stock_data(ticker, start_date, end_date)\n",
    "\n",
    "# Prepare features\n",
    "aligned_data, features = prepare_features(stock_data)\n",
    "\n",
    "# Train HMM\n",
    "n_states = 2\n",
    "hmm_model, hidden_states = train_hmm(features, n_states)\n",
    "\n",
    "print(\"Hidden states shape:\", hidden_states.shape)  # Should be (2259,)\n",
    "# Plot Hidden States \n",
    "aligned_data = aligned_data.copy()  # Ensure it's a standalone DataFrame\n",
    "aligned_data['State'] = hidden_states\n",
    "aligned_data['Signal'] = aligned_data['State'].apply(lambda x: 1 if x == 0 else -1)  # Buy in state 0, sell in others\n",
    "aligned_data['Strategy Returns'] = aligned_data['Signal'].shift(1) * aligned_data['Returns']\n",
    "calculate_metrics(aligned_data)\n",
    "plot_hidden_states(aligned_data, hidden_states, n_states)\n",
    "\n",
    "# Simulate Trading Strategy \n",
    "simulate_trading(aligned_data, hidden_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d85bed5-2535-4284-aa32-fa5a7c3aa05c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b17fb4e-4602-4a1a-b59e-fb9bf9aca949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
